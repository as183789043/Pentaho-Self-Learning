# Pentaho-Self-Learning
This project demonstrates how to use Pentaho Data Integration (PDI) to perform ETL operations and transform multiple data sources, based on a Udemy course

# This project goal
![image](https://github.com/user-attachments/assets/b78af872-5daa-48f3-ad65-936ec7f267b3)

**Important:**
* Verify the source data paths before running the transformations.
* Note: This project does not include configurations for proper Excel output or error notification emails.

## Prerequest
- Pentaho(PDI-ce)
- AWS CLI(token use)
- AWS S3
- Postgres SQL(pgAdmin)


## Screenshot  
#### AWS S3 Bucket(Hadoop file)
![image](https://github.com/user-attachments/assets/6704f1c6-5968-4cdf-9b4b-d8b5d503e575)

#### Jon flow
![image](https://github.com/user-attachments/assets/c0d7bb37-da56-41d0-858b-bcd3b854c01b)

#### Transformation  flow
- Customer data
  ![image](https://github.com/user-attachments/assets/2670076e-34bc-45b8-a84f-a1725bc536d5)
- Product data
  ![image](https://github.com/user-attachments/assets/95a16082-b10c-401f-a680-fbc28bb52f0a)
- Sales data
  ![image](https://github.com/user-attachments/assets/d1e48249-4074-4e95-abeb-71b5f9410515)


#### DB query results
![image](https://github.com/user-attachments/assets/4293be2d-74d6-4b30-9331-5ff33c74d586)

  



